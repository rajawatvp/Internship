{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82035e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af37bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException,ElementNotVisibleException,ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a0097",
   "metadata": {},
   "source": [
    "#### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "`Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos` \n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A)Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7737a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64232f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the empty list\n",
    "\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28319375",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the rank of the youtube video \n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in rank_tag[0:30]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    rank.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e687b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the name of the video\n",
    "\n",
    "name_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in name_tag[0:30]:\n",
    "        v_name=i.text.split('[')\n",
    "        name.append(v_name[0])\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    name.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the artist\n",
    "\n",
    "artist_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in artist_tag[0:30]:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the date of vivdeo post\n",
    "\n",
    "date_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in date_tag[0:30]:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    upload_date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the number of views on the videoes\n",
    "\n",
    "view_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in view_tag[0:30]:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62220558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data \n",
    "\n",
    "most_viewed_youtube_videos=pd.DataFrame({'Rank':rank,'Video Name':name,'Artist':artist,'Upload Date':upload_date,'Views':views})\n",
    "most_viewed_youtube_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d94086",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "`Url = https://www.bcci.tv/`\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Series\n",
    "\n",
    "B) Place\n",
    "\n",
    "C) Date\n",
    "\n",
    "D) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0959c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv'\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ea145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the empty list\n",
    "\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "evevnt_time=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5814473",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on INTERNATIONAL navigation\n",
    "driver.find_element(By.XPATH,\"/html/body/header/div[3]/ul/li[1]/button\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a6a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f280e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scroll the pages to scrape complete data\n",
    "\n",
    "time.sleep(3)\n",
    "for _ in range(1):\n",
    "    driver.execute_script(\"window.scrollBy(0,10)\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e90af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the upcoming series data\n",
    "\n",
    "series_tag=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "try:\n",
    "    for i in series_tag:        \n",
    "        series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  scrape the venue of the upcoming series\n",
    "\n",
    "place_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-place\"]/span[1]')\n",
    "try:\n",
    "    for i in place_tag:\n",
    "        place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    place.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the date of series begins\n",
    "\n",
    "date_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-info\"]/div[1]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the time of broadcast series\n",
    "\n",
    "time_tag=driver.find_elements(By.XPATH,'//div[@class=\"match-time ng-binding\"]')\n",
    "try:\n",
    "    for i in time_tag:\n",
    "        evevnt_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    evevnt_time.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(series))\n",
    "print(len(place))\n",
    "print(len(date))\n",
    "print(len(evevnt_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91bd87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data \n",
    "\n",
    "International_fixtures=pd.DataFrame({'Series':series,'Place':place,'Date':date,'Time':evevnt_time})\n",
    "International_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa9f43",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "`Url = http://statisticstimes.com/`\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.statisticstimes.com'\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb307bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## go to the Economy page\n",
    "\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "try:\n",
    "    economy.click()\n",
    "    driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[1]/div[2]/div[2]/div[1]/a[3]').click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dca3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## close the add if there any on the loaded page\n",
    "\n",
    "time.sleep(3)\n",
    "try:\n",
    "    ads=driver.find_element(By.XPATH,'//div[@class=\"ns-dbyfr-e-19 button-common close-button\"]')\n",
    "    ads.click()\n",
    "    gdp = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    driver.get('https://www.statisticstimes.com/economy/india/indian-states-gdp.php')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f49012",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the empty list\n",
    "\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_18_19=[]\n",
    "GSDP_19_20=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the rank of the states\n",
    "\n",
    "state_rank=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in state_rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the name of the states\n",
    "\n",
    "state_name=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in state_name:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the GDP's for the year 2018-19 of the states\n",
    "\n",
    "GSDP_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in GSDP_18_19_tag:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10271f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the GDP's for the year 2019-20 of the states\n",
    "\n",
    "GSDP_19_20_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in GSDP_19_20_tag:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_19_20.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fae2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the Share contribution for the year 2018-19 of the states\n",
    "\n",
    "share_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in share_18_19_tag:\n",
    "        Share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share_18_19.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the GDP's in Billions of the states\n",
    "\n",
    "GDP_billion_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "try:\n",
    "    for i in GDP_billion_tag:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data\n",
    "\n",
    "StateWise_GDP_Report=pd.DataFrame({'Rank':Rank,'State':State,'GSDP 18-19':GSDP_18_19,'GSDP 19-20':GSDP_19_20,'Share 18-19':Share_18_19,'GDP billion':GDP_billion})\n",
    "StateWise_GDP_Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b0efe",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com. \n",
    "`Url = https://github.com/`\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com/\"\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b585bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on explore sub menu\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/button')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Trending under explore sub menu\n",
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the empty lists\n",
    "\n",
    "Repository_title= []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the title of the github repository\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"text-normal\"]'):\n",
    "    Repository_title.append(i.text.replace('/',''))\n",
    "\n",
    "## scrape the discription of the github repository\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\"):\n",
    "    Repository_description.append(i.text)\n",
    "\n",
    "## scrape the contributors count of the github repository    \n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[2][@class=\"Link Link--muted d-inline-block mr-3\"]'):\n",
    "    Contributors_count.append(i.text)\n",
    "    \n",
    "## scrape the language used in the github repository    \n",
    "    \n",
    "lang = driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/span/span[2]')\n",
    "for i in lang:\n",
    "    try:\n",
    "        temp = driver.find_element(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "        Language_used.append(i.text.replace('\\n*',''))\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('-')\n",
    "    \n",
    "    \n",
    "print(len(Repository_title),len(Repository_description),len(Contributors_count),len(Language_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data\n",
    "\n",
    "github_trending_repository=pd.DataFrame({\"Repository_title\":Repository_title,\"Repository_description\":Repository_description,\"Language_used\":Language_used,\"Contributors_count\":Contributors_count})\n",
    "github_trending_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a156f",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com\n",
    "`Url = https:/www.billboard.com/`\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63340a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com'\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nav=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a\")\n",
    "nav.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac531ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot 100 songs\n",
    "hot_100=driver.find_element(By.XPATH,'/html/body/div[4]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e352909",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create empty list\n",
    "\n",
    "Name=[]\n",
    "Artist=[]\n",
    "rank=[]\n",
    "\n",
    "#Scraping name\n",
    "Name_tag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#Scraping artist\n",
    "Artist_tag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "for i in Artist_tag:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "#Scraping rank\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "for i in rankTag[:3]:\n",
    "    rank.append(i.text )\n",
    "    \n",
    "#Scraping name\n",
    "Rank=[]\n",
    "nameTag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in nameTag:\n",
    "    Name.append(i.text )\n",
    "\n",
    "#Scraping artist\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in artistTag:\n",
    "    Artist.append(i.text )\n",
    "\n",
    "#Scraping rank\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "for i in RankTag:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "    \n",
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)\n",
    "        \n",
    "# slicing Data\n",
    "last_week_rank=Rank[0::3]\n",
    "last_week_rank.insert(0,rank[0])\n",
    "peak_rank=Rank[1::3]\n",
    "peak_rank.insert(0,rank[1])\n",
    "weeks_on_board=Rank[2::3]\n",
    "weeks_on_board.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfe7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data\n",
    "\n",
    "Top_100_songs_data =pd.DataFrame({\"Song_name\":Name[:100],\"Artist_name\":Artist[:100],\"Last Week Rank\":last_week_rank[0:100],\"Peak Rank\":peak_rank[0:100],\"Weeks On Board\":weeks_on_board[0:100]})\n",
    "Top_100_songs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328b441",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest selling novels.\n",
    "`Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/`\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960af1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the empty list\n",
    "\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "genre=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the book names\n",
    "\n",
    "b_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[2]')\n",
    "try:\n",
    "    for i in b_name:\n",
    "        book_name.append(i.text)\n",
    "except:\n",
    "    book_name.append(\"-\")\n",
    "    \n",
    "\n",
    "## scrape the author name\n",
    "    \n",
    "a_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[3]')\n",
    "try:\n",
    "    for i in a_name:\n",
    "        author_name.append(i.text)\n",
    "except:\n",
    "    author_name.append(\"-\")\n",
    "\n",
    "## scrape the number of volume sold    \n",
    "    \n",
    "v_sold=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[4]')\n",
    "try:\n",
    "    for i in v_sold:\n",
    "        volumes_sold.append(i.text)\n",
    "except:\n",
    "    volumes_sold.append(\"-\")\n",
    "    \n",
    "    \n",
    "## scrape the publishers data\n",
    "    \n",
    "b_publisher=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[5]')\n",
    "try:\n",
    "    for i in b_publisher:\n",
    "        publisher.append(i.text)\n",
    "except:\n",
    "    publisher.append(\"-\")\n",
    "\n",
    "    \n",
    "## scrape the genre of the book\n",
    "    \n",
    "b_genre=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[6]')\n",
    "try:\n",
    "    for i in b_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4dac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the dataframe to store the scraped data\n",
    "\n",
    "Highest_selling_novels=pd.DataFrame({'Book Name':book_name,'Author Name':author_name,'Volumes sold':volumes_sold,'Publisher':publisher,'Genre':genre})\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686b05d",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "`Url = https://www.imdb.com/list/ls095964455/`\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1172288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this url is not working the loaded page show the error 404\n",
    "\n",
    "url = 'https://www.imdb.com/list/ls095964455/' \n",
    "\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb264c",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "`Url = https://www.imdb.com/list/ls095964455/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### due to Url is not accessing question:7 can not be solved "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6873a",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories.\n",
    "`Url = https://archive.ics.uci.edu/`\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07cf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/\"\n",
    "#connect to driver\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb5e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on show all dataset page\n",
    "\n",
    "page = driver.find_element(By.XPATH,\"//a[@class='btn-primary btn']\")\n",
    "page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the dataset name\n",
    "\n",
    "DATASET_Name = driver.find_elements(By.XPATH, \"//a[@class='link-hover link text-xl font-semibold'] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8ce34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "Dataset_name = []\n",
    "\n",
    "for d in DATASET_Name:\n",
    "    Dataset_name.append(d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6599e4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris',\n",
       " 'Dry Bean',\n",
       " 'Heart Disease',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Raisin',\n",
       " 'Adult',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Wine',\n",
       " 'Wine Quality',\n",
       " 'Bank Marketing']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6b7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the dataset type\n",
    "\n",
    "DATA_Type = driver.find_elements(By.XPATH,'//div[2][@class=\"col-span-3 flex items-center gap-2\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c33aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "Data_type = []\n",
    "\n",
    "for t in DATA_Type:\n",
    "    Data_type.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324df02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tabular',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Tabular',\n",
       " 'Multivariate',\n",
       " 'Multivariate']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the dataset task\n",
    "\n",
    "TASK = driver.find_elements(By.XPATH,'//div[1][@class=\"col-span-3 flex items-center gap-2\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9383acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "Task =[]\n",
    "\n",
    "for s in TASK:\n",
    "    Task.append(s.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4487ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification, Regression',\n",
       " 'Classification']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13221b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]\")\n",
    "expand.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cd0d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the Attribute of dataset \n",
    "\n",
    "ATTRIBUTE_TYPE = driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db584b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "Attribute_type = []\n",
    "\n",
    "for t in ATTRIBUTE_TYPE:\n",
    "    Attribute_type.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3484a54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Real',\n",
       " 'Integer, Real',\n",
       " 'Categorical, Integer, Real',\n",
       " 'Real',\n",
       " 'Real, Integer',\n",
       " 'Categorical, Integer',\n",
       " 'Real',\n",
       " 'Integer, Real',\n",
       " 'Real',\n",
       " 'Categorical, Integer']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attribute_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a1c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the number of instances of dataset \n",
    "\n",
    "NO_OF_INSTANCES = driver.find_elements(By.XPATH,'//div[3][@class=\"col-span-3 flex items-center gap-2\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc947171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "No_of_instances = []\n",
    "\n",
    "for n in NO_OF_INSTANCES:\n",
    "    No_of_instances.append(n.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8c825a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['150 Instances',\n",
       " '13.61K Instances',\n",
       " '303 Instances',\n",
       " '3.81K Instances',\n",
       " '900 Instances',\n",
       " '48.84K Instances',\n",
       " '569 Instances',\n",
       " '178 Instances',\n",
       " '4.9K Instances',\n",
       " '45.21K Instances']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_of_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f944c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the number of Attributes of dataset\n",
    "\n",
    "NO_OF_ATTRIBUTE = driver.find_elements(By.XPATH,'//div[4][@class=\"col-span-3 flex items-center gap-2\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af192ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "No_of_attribute = []\n",
    "\n",
    "for o in NO_OF_ATTRIBUTE:\n",
    "    No_of_attribute.append(o.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61c9ce95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 Features',\n",
       " '16 Features',\n",
       " '13 Features',\n",
       " '7 Features',\n",
       " '8 Features',\n",
       " '14 Features',\n",
       " '30 Features',\n",
       " '13 Features',\n",
       " '12 Features',\n",
       " '17 Features']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_of_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e2eb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scrape the year of posted of dataset\n",
    "\n",
    "YEAR = driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f25213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save scrapped data in the list\n",
    "\n",
    "Year = []\n",
    "\n",
    "for y in YEAR:\n",
    "    Year.append(y.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "867b58a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7/1/1988',\n",
       " '9/14/2020',\n",
       " '7/1/1988',\n",
       " '10/6/2019',\n",
       " '8/14/2023',\n",
       " '5/1/1996',\n",
       " '11/1/1995',\n",
       " '7/1/1991',\n",
       " '10/7/2009',\n",
       " '2/14/2012']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a78ee99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset name     Data type  \\\n",
       "0                                  Iris       Tabular   \n",
       "1                              Dry Bean  Multivariate   \n",
       "2                         Heart Disease  Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)  Multivariate   \n",
       "4                                Raisin  Multivariate   \n",
       "5                                 Adult  Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate   \n",
       "7                                  Wine       Tabular   \n",
       "8                          Wine Quality  Multivariate   \n",
       "9                        Bank Marketing  Multivariate   \n",
       "\n",
       "                         Task              Attribute type   No of instances  \\\n",
       "0              Classification                        Real     150 Instances   \n",
       "1              Classification               Integer, Real  13.61K Instances   \n",
       "2              Classification  Categorical, Integer, Real     303 Instances   \n",
       "3              Classification                        Real   3.81K Instances   \n",
       "4              Classification               Real, Integer     900 Instances   \n",
       "5              Classification        Categorical, Integer  48.84K Instances   \n",
       "6              Classification                        Real     569 Instances   \n",
       "7              Classification               Integer, Real     178 Instances   \n",
       "8  Classification, Regression                        Real    4.9K Instances   \n",
       "9              Classification        Categorical, Integer  45.21K Instances   \n",
       "\n",
       "  No of attribute       Year  \n",
       "0      4 Features   7/1/1988  \n",
       "1     16 Features  9/14/2020  \n",
       "2     13 Features   7/1/1988  \n",
       "3      7 Features  10/6/2019  \n",
       "4      8 Features  8/14/2023  \n",
       "5     14 Features   5/1/1996  \n",
       "6     30 Features  11/1/1995  \n",
       "7     13 Features   7/1/1991  \n",
       "8     12 Features  10/7/2009  \n",
       "9     17 Features  2/14/2012  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the dataframe to store the scraped data\n",
    "\n",
    "UCI_machine_learning = pd.DataFrame({'Dataset name':Dataset_name,' Data type':Data_type,'Task':Task,'Attribute type':Attribute_type,'No of instances':No_of_instances,'No of attribute':No_of_attribute,'Year':Year})\n",
    "UCI_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe078b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ________ End of the Assignment _____________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
